{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83cd888b-e6e4-415a-bb9a-22c23a183c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 30 flights into 21 training/validation and 9 test samples.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_synthetic_flights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 146>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m epochs_per_fold \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Directories to save metrics, models, and plots\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m metrics_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./metrics/mlp-full-augmented_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_synthetic_flights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    147\u001b[0m plots_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./plots/mlp-full-augmented_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_synthetic_flights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m models_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/mlp-full-augmented_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_synthetic_flights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_synthetic_flights' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Defining the State columns\n",
    "columns = ['ALT(m)', 'Phi(deg)', 'Theta(deg)', 'Psi(deg)', 'Radial(deg)', 'Distance(m)', 'DeltaAlt:Anv-Tgt(m)']\n",
    "\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "# Function to load and process flight data\n",
    "def load_and_process_flight_data(file_paths):\n",
    "    flights = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path, delimiter='\\t')\n",
    "        if 'Time(milli)' in df.columns:\n",
    "            df = df.drop(columns=['Time(milli)'])\n",
    "        flights.append(df)\n",
    "    return flights\n",
    "\n",
    "# Function to create state-action pairs for training\n",
    "def create_state_action_pairs(flight_data):\n",
    "    states = []\n",
    "    actions = []\n",
    "    for df in flight_data:\n",
    "        state = df[columns].values\n",
    "        action = df[['JX', 'JY', 'Throttle']].values\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "    return states, actions  # Return lists of arrays\n",
    "\n",
    "# Function to plot actual vs predicted actions with mean and standard deviation\n",
    "def plot_trajectory_with_mean_std(actual_actions_list, predicted_actions_list, plots_dir):\n",
    "    actual_actions = np.array(actual_actions_list)\n",
    "    predicted_actions = np.array(predicted_actions_list)\n",
    "\n",
    "    # Adjust time steps to handle different lengths\n",
    "    max_time_steps = max([actions.shape[0] for actions in actual_actions_list])\n",
    "    time_steps = np.arange(max_time_steps)\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    actual_padded = np.array([np.pad(actions, ((0, max_time_steps - actions.shape[0]), (0, 0)), 'edge') for actions in actual_actions_list])\n",
    "    predicted_padded = np.array([np.pad(actions, ((0, max_time_steps - actions.shape[0]), (0, 0)), 'edge') for actions in predicted_actions_list])\n",
    "\n",
    "    # Calculate mean and std for actual and predicted actions\n",
    "    actual_mean = np.mean(actual_padded, axis=0)\n",
    "    actual_std = np.std(actual_padded, axis=0)\n",
    "    predicted_mean = np.mean(predicted_padded, axis=0)\n",
    "    predicted_std = np.std(predicted_padded, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot JX\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(time_steps, actual_mean[:, 0], label='Actual JX (Mean)', color='blue')\n",
    "    plt.fill_between(time_steps, actual_mean[:, 0] - actual_std[:, 0], actual_mean[:, 0] + actual_std[:, 0], color='blue', alpha=0.2, label='Actual JX (± Std)')\n",
    "    plt.plot(time_steps, predicted_mean[:, 0], label='Predicted JX (Mean)', linestyle='--', color='red')\n",
    "    plt.fill_between(time_steps, predicted_mean[:, 0] - predicted_std[:, 0], predicted_mean[:, 0] + predicted_std[:, 0], color='red', alpha=0.2, label='Predicted JX (± Std)')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('JX')\n",
    "    plt.legend(loc='lower center', fontsize='x-small', ncol=2, handlelength=2.5, handletextpad=1.5)\n",
    "\n",
    "    # Plot JY\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(time_steps, actual_mean[:, 1], label='Actual JY (Mean)', color='blue')\n",
    "    plt.fill_between(time_steps, actual_mean[:, 1] - actual_std[:, 1], actual_mean[:, 1] + actual_std[:, 1], color='blue', alpha=0.2, label='Actual JY (± Std)')\n",
    "    plt.plot(time_steps, predicted_mean[:, 1], label='Predicted JY (Mean)', linestyle='--', color='red')\n",
    "    plt.fill_between(time_steps, predicted_mean[:, 1] - predicted_std[:, 1], predicted_mean[:, 1] + predicted_std[:, 1], color='red', alpha=0.2, label='Predicted JY (± Std)')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('JY')\n",
    "    plt.legend(loc='lower center', fontsize='x-small', ncol=2, handlelength=2.5, handletextpad=1.5)\n",
    "\n",
    "    # Plot Throttle\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(time_steps, actual_mean[:, 2], label='Actual Throttle (Mean)', color='blue')\n",
    "    plt.fill_between(time_steps, actual_mean[:, 2] - actual_std[:, 2], actual_mean[:, 2] + actual_std[:, 2], color='blue', alpha=0.2, label='Actual Throttle (± Std)')\n",
    "    plt.plot(time_steps, predicted_mean[:, 2], label='Predicted Throttle (Mean)', linestyle='--', color='red')\n",
    "    plt.fill_between(time_steps, predicted_mean[:, 2] - predicted_std[:, 2], predicted_mean[:, 2] + predicted_std[:, 2], color='red', alpha=0.2, label='Predicted Throttle (± Std)')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Throttle')\n",
    "    plt.legend(loc='lower center', fontsize='x-small', ncol=2, handlelength=2.5, handletextpad=1.5)\n",
    "\n",
    "    plt.suptitle('Trajectory Comparison: Actual vs Predicted with Mean and Standard Deviation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'trajectory_comparison_mean_std.png'), format='png', dpi=500)\n",
    "    plt.close()\n",
    "\n",
    "# Directory containing the adjusted flight data files\n",
    "adjusted_data_directory = './data/adjusted_flights/'\n",
    "adjusted_file_pattern = os.path.join(adjusted_data_directory, 'SimuladorDeVoo_*.txt')\n",
    "adjusted_files = glob.glob(adjusted_file_pattern)\n",
    "\n",
    "# Load and process the adjusted flight data\n",
    "flight_data = load_and_process_flight_data(adjusted_files)\n",
    "\n",
    "# Split the flight data into training/validation and test sets\n",
    "flight_data_train_val, flight_data_test = train_test_split(flight_data, test_size=0.30, random_state=42)\n",
    "print(f'Split {len(flight_data)} flights into {len(flight_data_train_val)} training/validation and {len(flight_data_test)} test samples.')\n",
    "\n",
    "# Create state-action pairs for training/validation and testing\n",
    "states_train_val_list, actions_train_val_list = create_state_action_pairs(flight_data_train_val)\n",
    "states_test_list, actions_test_list = create_state_action_pairs(flight_data_test)\n",
    "\n",
    "# Concatenate all flights data for training/validation\n",
    "states_train_val = np.concatenate(states_train_val_list, axis=0)\n",
    "actions_train_val = np.concatenate(actions_train_val_list, axis=0)\n",
    "\n",
    "# Concatenate all flights data for testing\n",
    "states_test = np.concatenate(states_test_list, axis=0)\n",
    "actions_test = np.concatenate(actions_test_list, axis=0)\n",
    "\n",
    "# Normalize the data using training data mean and std\n",
    "state_mean = np.mean(states_train_val, axis=0)\n",
    "state_std = np.std(states_train_val, axis=0)\n",
    "states_train_val = (states_train_val - state_mean) / state_std\n",
    "\n",
    "# Normalize test data using the same mean and std\n",
    "states_test = (states_test - state_mean) / state_std\n",
    "\n",
    "# Set random seed for cross-validation\n",
    "cv_seed = 42\n",
    "set_seed(cv_seed)\n",
    "\n",
    "# K-Fold Cross Validation on training/validation data\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=cv_seed)\n",
    "\n",
    "fold_no = 1\n",
    "metrics_cv_list = []\n",
    "epochs_per_fold = []\n",
    "\n",
    "# Directories to save metrics, models, and plots\n",
    "metrics_dir = f'./metrics/mlp-baseline/'\n",
    "plots_dir = f'./plots/mlp-baseline/'\n",
    "models_dir = f'./models/mlp-baseline/'\n",
    "os.makedirs(metrics_dir, exist_ok=True)\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "for train_index, val_index in kf.split(states_train_val):\n",
    "    X_train, X_val = states_train_val[train_index], states_train_val[val_index]\n",
    "    y_train, y_val = actions_train_val[train_index], actions_train_val[val_index]\n",
    "\n",
    "    # Define the Feedforward Neural Network model\n",
    "    model = Sequential([\n",
    "        Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(y_train.shape[1])  # Output layer\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.00001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "    # Measure training time\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    # Train the model with validation and early stopping\n",
    "    history = model.fit(X_train, y_train, epochs=int(1e6), batch_size=32,\n",
    "                        validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    train_end_time = time.time()\n",
    "    training_time = train_end_time - train_start_time\n",
    "\n",
    "    # Record the number of epochs used before early stopping\n",
    "    epochs_per_fold.append(len(history.history['loss']))\n",
    "\n",
    "    # Measure inference time on validation data\n",
    "    inference_start_time = time.time()\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    # Predict actions on the validation set\n",
    "    predicted_actions = model.predict(X_val, verbose=0)\n",
    "\n",
    "    inference_end_time = time.time()\n",
    "    inference_time = inference_end_time - inference_start_time\n",
    "\n",
    "    print(f'Fold {fold_no} - Training Time: {training_time:.4f} seconds, Inference Time: {inference_time:.4f} seconds')\n",
    "\n",
    "    # Calculate MSE, RMSE, MAE, and R² on validation data\n",
    "    mse = mean_squared_error(y_val, predicted_actions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_val, predicted_actions)\n",
    "    r2 = r2_score(y_val, predicted_actions)\n",
    "\n",
    "    # Append metrics and timing to list\n",
    "    metrics_cv_list.append({\n",
    "        'fold': fold_no,\n",
    "        'loss': val_loss,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'training_time': training_time,\n",
    "        'inference_time': inference_time\n",
    "    })\n",
    "\n",
    "    print(f'Fold {fold_no} - Validation MSE: {mse}')\n",
    "    print(f'Fold {fold_no} - Validation RMSE: {rmse}')\n",
    "    print(f'Fold {fold_no} - Validation MAE: {mae}')\n",
    "    print(f'Fold {fold_no} - Validation R²: {r2}')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Model Loss - Fold {fold_no}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(plots_dir, f'loss_fold_{fold_no}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save the model using the native Keras format\n",
    "    model.save(os.path.join(models_dir, f'model_fold_{fold_no}.keras'))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Calculate the average number of epochs from cross-validation\n",
    "avg_epochs = int(np.mean(epochs_per_fold))\n",
    "print(f'Average number of epochs from cross-validation: {avg_epochs}')\n",
    "\n",
    "# Convert metrics_cv_list to DataFrame\n",
    "metrics_cv_df = pd.DataFrame(metrics_cv_list)\n",
    "\n",
    "# Calculate mean and std for each metric\n",
    "mean_metrics_cv = metrics_cv_df.mean(numeric_only=True)\n",
    "std_metrics_cv = metrics_cv_df.std(numeric_only=True)\n",
    "\n",
    "# Add the fold column for mean and std\n",
    "mean_metrics_cv['fold'] = 'mean'\n",
    "std_metrics_cv['fold'] = 'std'\n",
    "\n",
    "# Convert mean and std to DataFrame\n",
    "mean_metrics_cv_df = pd.DataFrame([mean_metrics_cv])\n",
    "std_metrics_cv_df = pd.DataFrame([std_metrics_cv])\n",
    "\n",
    "# Append mean and std rows to the metrics_cv_df\n",
    "metrics_cv_df = pd.concat([metrics_cv_df, mean_metrics_cv_df, std_metrics_cv_df], ignore_index=True)\n",
    "\n",
    "# Save cross-validation metrics DataFrame to CSV\n",
    "metrics_cv_df.to_csv(os.path.join(metrics_dir, 'cross_validation_metrics.csv'), index=False)\n",
    "\n",
    "# Now, train the final model using different seeds\n",
    "final_model_metrics_list = []\n",
    "\n",
    "seeds = [43, 44, 45, 46, 47]\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Train the final model using the average number of epochs on the full training/validation data\n",
    "    final_model = Sequential([\n",
    "        Dense(128, input_dim=states_train_val.shape[1], activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(actions_train_val.shape[1])  # Output layer\n",
    "    ])\n",
    "\n",
    "    # Compile the final model\n",
    "    final_model.compile(optimizer=Adam(learning_rate=0.00001), loss='mse')\n",
    "\n",
    "    # Measure training time for the final model\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    # Train the final model without early stopping\n",
    "    final_model.fit(states_train_val, actions_train_val, epochs=avg_epochs, batch_size=32, verbose=0)\n",
    "\n",
    "    train_end_time = time.time()\n",
    "    final_training_time = train_end_time - train_start_time\n",
    "\n",
    "    print(f'Final Model (Seed {seed}) - Training Time: {final_training_time:.4f} seconds')\n",
    "\n",
    "    # Measure inference time on test data for the final model\n",
    "    inference_start_time = time.time()\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    final_loss = final_model.evaluate(states_test, actions_test, verbose=0)\n",
    "\n",
    "    # Predict actions on the test set using the final model\n",
    "    final_predicted_actions = final_model.predict(states_test, verbose=0)\n",
    "\n",
    "    inference_end_time = time.time()\n",
    "    final_inference_time = inference_end_time - inference_start_time\n",
    "\n",
    "    print(f'Final Model (Seed {seed}) - Inference Time: {final_inference_time:.4f} seconds')\n",
    "\n",
    "    # Calculate metrics for the final model on test data\n",
    "    final_mse = mean_squared_error(actions_test, final_predicted_actions)\n",
    "    final_rmse = np.sqrt(final_mse)\n",
    "    final_mae = mean_absolute_error(actions_test, final_predicted_actions)\n",
    "    final_r2 = r2_score(actions_test, final_predicted_actions)\n",
    "\n",
    "    # Append final model metrics and timing to list\n",
    "    final_model_metrics_list.append({\n",
    "        'seed': seed,\n",
    "        'loss': final_loss,\n",
    "        'mse': final_mse,\n",
    "        'rmse': final_rmse,\n",
    "        'mae': final_mae,\n",
    "        'r2': final_r2,\n",
    "        'training_time': final_training_time,\n",
    "        'inference_time': final_inference_time\n",
    "    })\n",
    "\n",
    "    print(f'Final Model (Seed {seed}) Metrics:')\n",
    "    print(f'Test MSE: {final_mse}')\n",
    "    print(f'Test RMSE: {final_rmse}')\n",
    "    print(f'Test MAE: {final_mae}')\n",
    "    print(f'Test R²: {final_r2}')\n",
    "\n",
    "    # Save the final model\n",
    "    final_model.save(os.path.join(models_dir, f'final_model_seed_{seed}.keras'))\n",
    "\n",
    "# After the loop over seeds, process the final model metrics\n",
    "final_model_metrics_df = pd.DataFrame(final_model_metrics_list)\n",
    "\n",
    "# Calculate mean and std for each metric\n",
    "mean_final_model_metrics = final_model_metrics_df.mean(numeric_only=True)\n",
    "std_final_model_metrics = final_model_metrics_df.std(numeric_only=True)\n",
    "\n",
    "# Add the seed column for mean and std\n",
    "mean_final_model_metrics['seed'] = 'mean'\n",
    "std_final_model_metrics['seed'] = 'std'\n",
    "\n",
    "# Convert mean and std to DataFrame\n",
    "mean_final_model_metrics_df = pd.DataFrame([mean_final_model_metrics])\n",
    "std_final_model_metrics_df = pd.DataFrame([std_final_model_metrics])\n",
    "\n",
    "# Append mean and std rows to the final_model_metrics_df\n",
    "final_model_metrics_df = pd.concat([final_model_metrics_df, mean_final_model_metrics_df, std_final_model_metrics_df], ignore_index=True)\n",
    "\n",
    "# Save final model metrics DataFrame to CSV\n",
    "final_model_metrics_df.to_csv(os.path.join(metrics_dir, 'final_model_metrics.csv'), index=False)\n",
    "\n",
    "# Optionally, plot the trajectory comparison using one of the final models (e.g., the last one)\n",
    "print(\"Predicting the test dataset using the final model...\")\n",
    "\n",
    "actual_actions_list = []\n",
    "predicted_actions_list = []\n",
    "\n",
    "for i, state_sequence in enumerate(states_test_list):\n",
    "    # Normalize the state sequence\n",
    "    state_sequence_normalized = (state_sequence - state_mean) / state_std\n",
    "\n",
    "    # Predict actions for the entire sequence\n",
    "    predicted_actions_full = final_model.predict(state_sequence_normalized, verbose=0)\n",
    "    actual_actions_full = actions_test_list[i]\n",
    "\n",
    "    actual_actions_list.append(actual_actions_full)\n",
    "    predicted_actions_list.append(predicted_actions_full)\n",
    "    print(f'Full flight trajectory {i+1} predicted and collected.')\n",
    "\n",
    "# Plot the mean and standard deviation for the collected trajectories\n",
    "plot_trajectory_with_mean_std(actual_actions_list, predicted_actions_list, plots_dir)\n",
    "print('Trajectory comparison plot with mean and standard deviation saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91080ed-cccf-4719-a013-6cb36944d350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
