{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83cd888b-e6e4-415a-bb9a-22c23a183c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 30 flights into 21 training/validation and 9 test samples.\n",
      "Fold 1 - Training Time: 116.6686 seconds, Inference Time: 1.0101 seconds\n",
      "Fold 1 - Validation MSE: 2.6022364258116855\n",
      "Fold 1 - Validation RMSE: 1.6131448868008371\n",
      "Fold 1 - Validation MAE: 0.6753783669415413\n",
      "Fold 1 - Validation R²: 0.9686942411933117\n",
      "Fold 2 - Training Time: 97.1894 seconds, Inference Time: 0.7601 seconds\n",
      "Fold 2 - Validation MSE: 3.1237565641096112\n",
      "Fold 2 - Validation RMSE: 1.767415221194389\n",
      "Fold 2 - Validation MAE: 0.6737251359937289\n",
      "Fold 2 - Validation R²: 0.9688659645595616\n",
      "Fold 3 - Training Time: 87.4123 seconds, Inference Time: 0.8615 seconds\n",
      "Fold 3 - Validation MSE: 3.01921874954664\n",
      "Fold 3 - Validation RMSE: 1.7375899256000076\n",
      "Fold 3 - Validation MAE: 0.6948409706923714\n",
      "Fold 3 - Validation R²: 0.9725411899691497\n",
      "Fold 4 - Training Time: 70.5815 seconds, Inference Time: 0.8618 seconds\n",
      "Fold 4 - Validation MSE: 7.3290056131546315\n",
      "Fold 4 - Validation RMSE: 2.707213625326718\n",
      "Fold 4 - Validation MAE: 1.0626320115583943\n",
      "Fold 4 - Validation R²: 0.9366763105509648\n",
      "Fold 5 - Training Time: 106.0720 seconds, Inference Time: 0.6584 seconds\n",
      "Fold 5 - Validation MSE: 3.0600707483665617\n",
      "Fold 5 - Validation RMSE: 1.7493057904113167\n",
      "Fold 5 - Validation MAE: 0.647371777744871\n",
      "Fold 5 - Validation R²: 0.9669979689305394\n",
      "Average number of epochs from cross-validation: 641\n",
      "Final Model (Seed 43) - Training Time: 75.2395 seconds\n",
      "Final Model (Seed 43) - Inference Time: 1.2538 seconds\n",
      "Final Model (Seed 43) Metrics:\n",
      "Test MSE: 3.4157440019871976\n",
      "Test RMSE: 1.848173152598857\n",
      "Test MAE: 0.7335682852787256\n",
      "Test R²: 0.9719638279913413\n",
      "Final Model (Seed 44) - Training Time: 74.0923 seconds\n",
      "Final Model (Seed 44) - Inference Time: 1.1808 seconds\n",
      "Final Model (Seed 44) Metrics:\n",
      "Test MSE: 2.870413163016702\n",
      "Test RMSE: 1.6942293714301797\n",
      "Test MAE: 0.6462964630541462\n",
      "Test R²: 0.9697250080969159\n",
      "Final Model (Seed 45) - Training Time: 78.0278 seconds\n",
      "Final Model (Seed 45) - Inference Time: 1.1632 seconds\n",
      "Final Model (Seed 45) Metrics:\n",
      "Test MSE: 2.96007588643238\n",
      "Test RMSE: 1.7204871073136179\n",
      "Test MAE: 0.6755292394503853\n",
      "Test R²: 0.9695052131662348\n",
      "Final Model (Seed 46) - Training Time: 74.6542 seconds\n",
      "Final Model (Seed 46) - Inference Time: 1.1389 seconds\n",
      "Final Model (Seed 46) Metrics:\n",
      "Test MSE: 2.991674841869893\n",
      "Test RMSE: 1.7296458718101497\n",
      "Test MAE: 0.689691060354714\n",
      "Test R²: 0.972948248388164\n",
      "Final Model (Seed 47) - Training Time: 71.1448 seconds\n",
      "Final Model (Seed 47) - Inference Time: 1.2963 seconds\n",
      "Final Model (Seed 47) Metrics:\n",
      "Test MSE: 2.8765132947296146\n",
      "Test RMSE: 1.6960286833451887\n",
      "Test MAE: 0.6620123255174745\n",
      "Test R²: 0.9724932296820348\n",
      "Predicting the test dataset using the final model...\n",
      "Full flight trajectory 1 predicted and collected.\n",
      "Full flight trajectory 2 predicted and collected.\n",
      "Full flight trajectory 3 predicted and collected.\n",
      "Full flight trajectory 4 predicted and collected.\n",
      "Full flight trajectory 5 predicted and collected.\n",
      "Full flight trajectory 6 predicted and collected.\n",
      "Full flight trajectory 7 predicted and collected.\n",
      "Full flight trajectory 8 predicted and collected.\n",
      "Full flight trajectory 9 predicted and collected.\n",
      "Trajectory comparison plot with mean and standard deviation saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import GRU, Dense, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Defining the State columns\n",
    "columns = ['ALT(m)', 'Phi(deg)', 'Theta(deg)', 'Psi(deg)', 'Vx(m/s)', 'Vy(m/s)', 'Vz(m/s)', 'P(deg/s)', 'Q(deg/s)', 'R(deg/s)', 'Nx(m/s2)', 'Ny(m/s2)', 'Nz(m/s2)', 'Radial(deg)', 'Distance(m)', 'DeltaAlt:Anv-Tgt(m)']\n",
    "\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "# Function to load and process flight data\n",
    "def load_and_process_flight_data(file_paths):\n",
    "    flights = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path, delimiter='\\t')\n",
    "        if 'Time(milli)' in df.columns:\n",
    "            df = df.drop(columns=['Time(milli)'])\n",
    "        flights.append(df)\n",
    "    return flights\n",
    "\n",
    "# Function to create subsequences from flight data for training\n",
    "def create_subsequences(flight_data, seq_length):\n",
    "    state_subsequences = []\n",
    "    action_subsequences = []\n",
    "    flight_ids = []\n",
    "    for flight_id, df in enumerate(flight_data):\n",
    "        states =  df[columns].values\n",
    "        actions = df[['JX', 'JY', 'Throttle']].values\n",
    "        num_subsequences = len(states) - seq_length + 1\n",
    "        for i in range(num_subsequences):\n",
    "            state_subsequence = states[i:i+seq_length]\n",
    "            action_subsequence = actions[i:i+seq_length]  # Now a sequence\n",
    "            state_subsequences.append(state_subsequence)\n",
    "            action_subsequences.append(action_subsequence)\n",
    "            flight_ids.append(flight_id)\n",
    "    return np.array(state_subsequences), np.array(action_subsequences), np.array(flight_ids)\n",
    "\n",
    "# Function to plot actual vs predicted actions with mean and standard deviation\n",
    "def plot_trajectory_with_mean_std(actual_actions_list, predicted_actions_list, plots_dir):\n",
    "    actual_actions = np.array(actual_actions_list)\n",
    "    predicted_actions = np.array(predicted_actions_list)\n",
    "\n",
    "    # Adjust time steps to handle different lengths\n",
    "    max_time_steps = max([actions.shape[0] for actions in actual_actions_list])\n",
    "    time_steps = np.arange(max_time_steps)\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    actual_padded = np.array([np.pad(actions, ((0, max_time_steps - actions.shape[0]), (0, 0)), 'edge') for actions in actual_actions_list])\n",
    "    predicted_padded = np.array([np.pad(actions, ((0, max_time_steps - actions.shape[0]), (0, 0)), 'edge') for actions in predicted_actions_list])\n",
    "\n",
    "    # Calculate mean and std for actual and predicted actions\n",
    "    actual_mean = np.mean(actual_padded, axis=0)\n",
    "    actual_std = np.std(actual_padded, axis=0)\n",
    "    predicted_mean = np.mean(predicted_padded, axis=0)\n",
    "    predicted_std = np.std(predicted_padded, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot JX\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(time_steps, actual_mean[:, 0], label='Actual JX (Mean)', color='blue')\n",
    "    plt.fill_between(time_steps, actual_mean[:, 0] - actual_std[:, 0], actual_mean[:, 0] + actual_std[:, 0], color='blue', alpha=0.2, label='Actual JX (± Std)')\n",
    "    plt.plot(time_steps, predicted_mean[:, 0], label='Predicted JX (Mean)', linestyle='--', color='red')\n",
    "    plt.fill_between(time_steps, predicted_mean[:, 0] - predicted_std[:, 0], predicted_mean[:, 0] + predicted_std[:, 0], color='red', alpha=0.2, label='Predicted JX (± Std)')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('JX')\n",
    "    plt.legend(loc='lower center', fontsize='x-small', ncol=2, handlelength=2.5, handletextpad=1.5)\n",
    "\n",
    "    # Plot JY\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(time_steps, actual_mean[:, 1], label='Actual JY (Mean)', color='blue')\n",
    "    plt.fill_between(time_steps, actual_mean[:, 1] - actual_std[:, 1], actual_mean[:, 1] + actual_std[:, 1], color='blue', alpha=0.2, label='Actual JY (± Std)')\n",
    "    plt.plot(time_steps, predicted_mean[:, 1], label='Predicted JY (Mean)', linestyle='--', color='red')\n",
    "    plt.fill_between(time_steps, predicted_mean[:, 1] - predicted_std[:, 1], predicted_mean[:, 1] + predicted_std[:, 1], color='red', alpha=0.2, label='Predicted JY (± Std)')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('JY')\n",
    "    plt.legend(loc='lower center', fontsize='x-small', ncol=2, handlelength=2.5, handletextpad=1.5)\n",
    "\n",
    "    # Plot Throttle\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(time_steps, actual_mean[:, 2], label='Actual Throttle (Mean)', color='blue')\n",
    "    plt.fill_between(time_steps, actual_mean[:, 2] - actual_std[:, 2], actual_mean[:, 2] + actual_std[:, 2], color='blue', alpha=0.2, label='Actual Throttle (± Std)')\n",
    "    plt.plot(time_steps, predicted_mean[:, 2], label='Predicted Throttle (Mean)', linestyle='--', color='red')\n",
    "    plt.fill_between(time_steps, predicted_mean[:, 2] - predicted_std[:, 2], predicted_mean[:, 2] + predicted_std[:, 2], color='red', alpha=0.2, label='Predicted Throttle (± Std)')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Throttle')\n",
    "    plt.legend(loc='lower center', fontsize='x-small', ncol=2, handlelength=2.5, handletextpad=1.5)\n",
    "\n",
    "    plt.suptitle('Trajectory Comparison: Actual vs Predicted with Mean and Standard Deviation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'trajectory_comparison_mean_std.png'), format='png', dpi=500)\n",
    "    plt.close()\n",
    "\n",
    "# Directory containing the adjusted flight data files\n",
    "adjusted_data_directory = './data/adjusted_flights/'\n",
    "adjusted_file_pattern = os.path.join(adjusted_data_directory, 'SimuladorDeVoo_*.txt')\n",
    "adjusted_files = glob.glob(adjusted_file_pattern)\n",
    "\n",
    "# Load and process the adjusted flight data\n",
    "flight_data = load_and_process_flight_data(adjusted_files)\n",
    "\n",
    "# Split the flight data into training/validation and test sets\n",
    "flight_data_train_val, flight_data_test = train_test_split(flight_data, test_size=0.30, random_state=42)\n",
    "print(f'Split {len(flight_data)} flights into {len(flight_data_train_val)} training/validation and {len(flight_data_test)} test samples.')\n",
    "\n",
    "# Define sequence length for training\n",
    "sequence_length = 5\n",
    "\n",
    "# Create subsequences from flight data for training\n",
    "state_subsequences_train_val, action_subsequences_train_val, flight_ids_train_val = create_subsequences(flight_data_train_val, sequence_length)\n",
    "\n",
    "# Create subsequences from flight data for test\n",
    "state_subsequences_test, action_subsequences_test, flight_ids_test = create_subsequences(flight_data_test, sequence_length)\n",
    "\n",
    "# Set random seed for cross-validation\n",
    "cv_seed = 42\n",
    "set_seed(cv_seed)\n",
    "\n",
    "# K-Fold Cross Validation on training/validation data\n",
    "# Get unique flight IDs\n",
    "unique_flight_ids = np.unique(flight_ids_train_val)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=cv_seed)\n",
    "\n",
    "fold_no = 1\n",
    "metrics_cv_list = []\n",
    "epochs_per_fold = []\n",
    "\n",
    "# Directories to save metrics, models, and plots\n",
    "metrics_dir = './metrics/gru-full/'\n",
    "plots_dir = './plots/gru-full/'\n",
    "models_dir = './models/gru-full/'\n",
    "os.makedirs(metrics_dir, exist_ok=True)\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "for train_flight_ids_idx, val_flight_ids_idx in kf.split(unique_flight_ids):\n",
    "    # Get flight IDs for training and validation\n",
    "    train_flight_ids = unique_flight_ids[train_flight_ids_idx]\n",
    "    val_flight_ids = unique_flight_ids[val_flight_ids_idx]\n",
    "\n",
    "    # Map flight IDs to indices in subsequences\n",
    "    train_indices = np.isin(flight_ids_train_val, train_flight_ids)\n",
    "    val_indices = np.isin(flight_ids_train_val, val_flight_ids)\n",
    "\n",
    "    # Select subsequences corresponding to training and validation flights\n",
    "    states_train, actions_train = state_subsequences_train_val[train_indices], action_subsequences_train_val[train_indices]\n",
    "    states_val, actions_val = state_subsequences_train_val[val_indices], action_subsequences_train_val[val_indices]\n",
    "\n",
    "    # Normalize the data using training data mean and std\n",
    "    state_mean = np.mean(states_train, axis=(0,1))\n",
    "    state_std = np.std(states_train, axis=(0,1))\n",
    "    states_train = (states_train - state_mean) / state_std\n",
    "    states_val = (states_val - state_mean) / state_std  # Use training mean and std\n",
    "\n",
    "    # Normalize the actions using training data mean and std\n",
    "    action_mean = np.mean(actions_train, axis=(0,1))\n",
    "    action_std = np.std(actions_train, axis=(0,1))\n",
    "    actions_train = (actions_train - action_mean) / action_std\n",
    "    actions_val = (actions_val - action_mean) / action_std  # Use training action mean and std\n",
    "\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, input_shape=(sequence_length, states_train.shape[2]), return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(actions_train.shape[2])))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "    # Measure training time\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    # Train the model with validation and early stopping\n",
    "    history = model.fit(states_train, actions_train, epochs=int(1e6), batch_size=64, \n",
    "                        validation_data=(states_val, actions_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    train_end_time = time.time()\n",
    "    training_time = train_end_time - train_start_time\n",
    "\n",
    "    # Record the number of epochs used\n",
    "    epochs_per_fold.append(len(history.history['loss']))\n",
    "\n",
    "    # Measure inference time\n",
    "    inference_start_time = time.time()\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss = model.evaluate(states_val, actions_val, verbose=0)\n",
    "\n",
    "    # Predict actions on the validation set\n",
    "    predicted_actions = model.predict(states_val, verbose=0)\n",
    "\n",
    "    inference_end_time = time.time()\n",
    "    inference_time = inference_end_time - inference_start_time\n",
    "\n",
    "    print(f'Fold {fold_no} - Training Time: {training_time:.4f} seconds, Inference Time: {inference_time:.4f} seconds')\n",
    "\n",
    "    # Reshape for metrics calculations\n",
    "    actions_val_reshaped = actions_val.reshape(-1, actions_val.shape[2])\n",
    "    predicted_actions_reshaped = predicted_actions.reshape(-1, predicted_actions.shape[2])\n",
    "\n",
    "    # Denormalize the actions for evaluation\n",
    "    actions_val_denorm = actions_val_reshaped * action_std + action_mean\n",
    "    predicted_actions_denorm = predicted_actions_reshaped * action_std + action_mean\n",
    "\n",
    "    # Calculate MSE, RMSE, MAE, R²\n",
    "    mse = mean_squared_error(actions_val_denorm, predicted_actions_denorm)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actions_val_denorm, predicted_actions_denorm)\n",
    "    r2 = r2_score(actions_val_denorm, predicted_actions_denorm)\n",
    "\n",
    "    # Append metrics and timing to list\n",
    "    metrics_cv_list.append({\n",
    "        'fold': fold_no,\n",
    "        'loss': val_loss,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'training_time': training_time,\n",
    "        'inference_time': inference_time\n",
    "    })\n",
    "\n",
    "    print(f'Fold {fold_no} - Validation MSE: {mse}')\n",
    "    print(f'Fold {fold_no} - Validation RMSE: {rmse}')\n",
    "    print(f'Fold {fold_no} - Validation MAE: {mae}')\n",
    "    print(f'Fold {fold_no} - Validation R²: {r2}')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Model Loss - Fold {fold_no}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(plots_dir, f'loss_fold_{fold_no}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save the model\n",
    "    model.save(os.path.join(models_dir, f'model_fold_{fold_no}.keras'))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Calculate the average number of epochs from cross-validation\n",
    "avg_epochs = int(np.mean(epochs_per_fold))\n",
    "print(f'Average number of epochs from cross-validation: {avg_epochs}')\n",
    "\n",
    "# Convert metrics_cv_list to DataFrame\n",
    "metrics_cv_df = pd.DataFrame(metrics_cv_list)\n",
    "\n",
    "# Calculate mean and std for each metric\n",
    "mean_metrics_cv = metrics_cv_df.mean(numeric_only=True)\n",
    "std_metrics_cv = metrics_cv_df.std(numeric_only=True)\n",
    "\n",
    "# Add the fold column for mean and std\n",
    "mean_metrics_cv['fold'] = 'mean'\n",
    "std_metrics_cv['fold'] = 'std'\n",
    "\n",
    "# Convert mean and std to DataFrame\n",
    "mean_metrics_cv_df = pd.DataFrame([mean_metrics_cv])\n",
    "std_metrics_cv_df = pd.DataFrame([std_metrics_cv])\n",
    "\n",
    "# Append mean and std rows to the metrics_cv_df\n",
    "metrics_cv_df = pd.concat([metrics_cv_df, mean_metrics_cv_df, std_metrics_cv_df], ignore_index=True)\n",
    "\n",
    "# Save cross-validation metrics DataFrame to CSV\n",
    "metrics_cv_df.to_csv(os.path.join(metrics_dir, 'cross_validation_metrics.csv'), index=False)\n",
    "\n",
    "# Now, train the final model using different seeds\n",
    "final_model_metrics_list = []\n",
    "\n",
    "seeds = [43, 44, 45, 46, 47]\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Normalize the full training data using its own mean and std\n",
    "    state_mean_full = np.mean(state_subsequences_train_val, axis=(0,1))\n",
    "    state_std_full = np.std(state_subsequences_train_val, axis=(0,1))\n",
    "    state_subsequences_train_val_normalized = (state_subsequences_train_val - state_mean_full) / state_std_full\n",
    "\n",
    "    action_mean_full = np.mean(action_subsequences_train_val, axis=(0,1))\n",
    "    action_std_full = np.std(action_subsequences_train_val, axis=(0,1))\n",
    "    action_subsequences_train_val_normalized = (action_subsequences_train_val - action_mean_full) / action_std_full\n",
    "\n",
    "    # Train the final model using the average number of epochs on the full training/validation data\n",
    "    final_model = Sequential()\n",
    "    final_model.add(GRU(128, input_shape=(sequence_length, state_subsequences_train_val_normalized.shape[2]), return_sequences=True))\n",
    "    final_model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "    final_model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "    final_model.add(TimeDistributed(Dense(action_subsequences_train_val_normalized.shape[2])))\n",
    "\n",
    "    # Compile the final model\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    final_model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    # Measure training time\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    # Train the final model for avg_epochs without early stopping\n",
    "    final_model.fit(state_subsequences_train_val_normalized, action_subsequences_train_val_normalized, epochs=avg_epochs, batch_size=64, verbose=0)\n",
    "\n",
    "    train_end_time = time.time()\n",
    "    final_training_time = train_end_time - train_start_time\n",
    "\n",
    "    print(f'Final Model (Seed {seed}) - Training Time: {final_training_time:.4f} seconds')\n",
    "\n",
    "    # Normalize the test data using the training data mean and std\n",
    "    state_subsequences_test_normalized = (state_subsequences_test - state_mean_full) / state_std_full\n",
    "    action_subsequences_test_normalized = (action_subsequences_test - action_mean_full) / action_std_full\n",
    "\n",
    "    # Measure inference time\n",
    "    inference_start_time = time.time()\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    final_loss = final_model.evaluate(state_subsequences_test_normalized, action_subsequences_test_normalized, verbose=0)\n",
    "\n",
    "    # Predict actions on the test set using the final model\n",
    "    final_predicted_actions = final_model.predict(state_subsequences_test_normalized, verbose=0)\n",
    "\n",
    "    inference_end_time = time.time()\n",
    "    final_inference_time = inference_end_time - inference_start_time\n",
    "\n",
    "    print(f'Final Model (Seed {seed}) - Inference Time: {final_inference_time:.4f} seconds')\n",
    "\n",
    "    # Reshape for metrics calculations\n",
    "    actions_test_reshaped = action_subsequences_test_normalized.reshape(-1, action_subsequences_test_normalized.shape[2])\n",
    "    final_predicted_actions_reshaped = final_predicted_actions.reshape(-1, final_predicted_actions.shape[2])\n",
    "\n",
    "    # Denormalize actions for evaluation\n",
    "    actions_test_denorm = actions_test_reshaped * action_std_full + action_mean_full\n",
    "    final_predicted_actions_denorm = final_predicted_actions_reshaped * action_std_full + action_mean_full\n",
    "\n",
    "    # Calculate metrics for the final model on test data\n",
    "    final_mse = mean_squared_error(actions_test_denorm, final_predicted_actions_denorm)\n",
    "    final_rmse = np.sqrt(final_mse)\n",
    "    final_mae = mean_absolute_error(actions_test_denorm, final_predicted_actions_denorm)\n",
    "    final_r2 = r2_score(actions_test_denorm, final_predicted_actions_denorm)\n",
    "\n",
    "    # Append final model metrics and timing to list\n",
    "    final_model_metrics_list.append({\n",
    "        'seed': seed,\n",
    "        'loss': final_loss,\n",
    "        'mse': final_mse,\n",
    "        'rmse': final_rmse,\n",
    "        'mae': final_mae,\n",
    "        'r2': final_r2,\n",
    "        'training_time': final_training_time,\n",
    "        'inference_time': final_inference_time\n",
    "    })\n",
    "\n",
    "    print(f'Final Model (Seed {seed}) Metrics:')\n",
    "    print(f'Test MSE: {final_mse}')\n",
    "    print(f'Test RMSE: {final_rmse}')\n",
    "    print(f'Test MAE: {final_mae}')\n",
    "    print(f'Test R²: {final_r2}')\n",
    "\n",
    "    # Save the final model\n",
    "    final_model.save(os.path.join(models_dir, f'final_model_seed_{seed}.keras'))\n",
    "\n",
    "# After the loop over seeds, process the final model metrics\n",
    "final_model_metrics_df = pd.DataFrame(final_model_metrics_list)\n",
    "\n",
    "# Calculate mean and std for each metric\n",
    "mean_final_model_metrics = final_model_metrics_df.mean(numeric_only=True)\n",
    "std_final_model_metrics = final_model_metrics_df.std(numeric_only=True)\n",
    "\n",
    "# Add the seed column for mean and std\n",
    "mean_final_model_metrics['seed'] = 'mean'\n",
    "std_final_model_metrics['seed'] = 'std'\n",
    "\n",
    "# Convert mean and std to DataFrame\n",
    "mean_final_model_metrics_df = pd.DataFrame([mean_final_model_metrics])\n",
    "std_final_model_metrics_df = pd.DataFrame([std_final_model_metrics])\n",
    "\n",
    "# Append mean and std rows to the final_model_metrics_df\n",
    "final_model_metrics_df = pd.concat([final_model_metrics_df, mean_final_model_metrics_df, std_final_model_metrics_df], ignore_index=True)\n",
    "\n",
    "# Save final model metrics DataFrame to CSV\n",
    "final_model_metrics_df.to_csv(os.path.join(metrics_dir, 'final_model_metrics.csv'), index=False)\n",
    "\n",
    "# Optionally, plot the trajectory comparison using one of the final models (e.g., the last one)\n",
    "print(\"Predicting the test dataset using the final model...\")\n",
    "\n",
    "# Prepare test sequences for full trajectory prediction\n",
    "state_sequences_test = []\n",
    "action_sequences_test = []\n",
    "\n",
    "for df in flight_data_test:\n",
    "    states =  df[columns].values\n",
    "    actions = df[['JX', 'JY', 'Throttle']].values\n",
    "    state_sequences_test.append(states)\n",
    "    action_sequences_test.append(actions)\n",
    "\n",
    "# Use the last trained final model for prediction\n",
    "final_model = final_model  # The last model trained in the loop\n",
    "\n",
    "# Predict full flight trajectories using the final model\n",
    "actual_actions_list = []\n",
    "predicted_actions_list = []\n",
    "\n",
    "for i, state_sequence in enumerate(state_sequences_test):\n",
    "    predicted_actions_full = []\n",
    "\n",
    "    num_steps = len(state_sequence)\n",
    "    for j in range(sequence_length - 1, num_steps):\n",
    "        window = state_sequence[j - sequence_length + 1:j + 1]\n",
    "        # Normalize window\n",
    "        window_normalized = (window - state_mean_full) / state_std_full\n",
    "        window_normalized = window_normalized.reshape(1, sequence_length, state_sequence.shape[1])\n",
    "        predicted_action = final_model.predict(window_normalized, verbose=0)\n",
    "        # Denormalize the predicted action\n",
    "        predicted_action_denorm = predicted_action[0, -1] * action_std_full + action_mean_full\n",
    "        predicted_actions_full.append(predicted_action_denorm)\n",
    "\n",
    "    # Pad the beginning to match the original sequence length\n",
    "    for _ in range(sequence_length - 1):\n",
    "        predicted_actions_full.insert(0, predicted_actions_full[0])\n",
    "\n",
    "    predicted_actions_full = np.array(predicted_actions_full)\n",
    "    actual_actions_full = action_sequences_test[i][:len(predicted_actions_full)]  # Align lengths\n",
    "\n",
    "    actual_actions_list.append(actual_actions_full)\n",
    "    predicted_actions_list.append(predicted_actions_full)\n",
    "    print(f'Full flight trajectory {i+1} predicted and collected.')\n",
    "\n",
    "# Plot the mean and standard deviation for the collected trajectories\n",
    "plot_trajectory_with_mean_std(actual_actions_list, predicted_actions_list, plots_dir)\n",
    "print('Trajectory comparison plot with mean and standard deviation saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
